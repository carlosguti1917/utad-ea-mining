# input {
#  file {
#    #https://www.elastic.co/guide/en/logstash/current/plugins-inputs-file.html
#    #default is TAIL which assumes more data will come into the file.
#    #change to mode => "read" if the file is a compelte file.  by default, the file will be removed once reading is complete -- backup your files if you need them.
#    mode => "tail"
#    path => "/usr/share/logstash/ingest_data/*"
#  }
# }

input {
  udp {
    #host => "192.168.0.15" # default 0.0.0.0
    port => 514
    #add_tag => ["kong"]
    tags => ["kongudp"]
  }
  tcp {
    # port => 9200 #aparentemente funciona
    port => 5000
    codec => json
    tags => ["kongtcp"]
  }  
}

# output {
#   elasticsearch {
#     hosts => ["192.168.0.15:9200"]  # Substitua pelo endereço do seu Elasticsearch
#     index => "kong-logs"  # Nome do índice onde os logs serão armazenados
#   }
# }

output {
 elasticsearch {
    #index => "logstash-%{+YYYY.MM.dd}"
    index => "konglog" 
    hosts=> "${ELASTIC_HOSTS}"
    #hosts => ["https://es01:9200"]
    user => "${ELASTIC_USER}"
    password => "${ELASTIC_PASSWORD}"
    cacert => "certs/ca/ca.crt"
    ssl_certificate_verification => false
 }
}

filter {
  # grok {
  #   match => {
  #     message => "%{HTTPDATE} %{IP:clientip} %{USERAGENT} %{HTTPVERB} %{URLPATH} %{HTTPSTATUS} %{BYTES_IN} %{BYTES_OUT} %{ELAPSED_TIME} %{kong_body}"
  #   }
  # }
  json {
    source => "message"
    add_field => {
      "kong_body" => "%{body}"
    }
    add_tag => ["kong"]
  }  
}





